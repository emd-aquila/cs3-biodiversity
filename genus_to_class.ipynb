{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d9e16aaf",
      "metadata": {
        "id": "d9e16aaf"
      },
      "source": [
        "# Genus/Species to Class Converter\n",
        "This notebook contains code to convert the genus/species listing from the BioTIME-DB to taxonomic class using Biopython and calling upon the NCBI, COL, GBIF, and WORMS databases, in that order."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary packages and get CSV file from GitHub"
      ],
      "metadata": {
        "id": "lrrHbca8zLWx"
      },
      "id": "lrrHbca8zLWx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages and set NCBI API information.\n",
        "!pip install biopython tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "from Bio import Entrez\n",
        "import time\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from getpass import getpass\n",
        "\n",
        "! wget https://raw.githubusercontent.com/emd-aquila/cs3-biodiversity/main/data/unique_genus_species.csv -O myfile.csv\n",
        "df_all = pd.read_csv(\"myfile.csv\")\n",
        "\n",
        "Entrez.email = \"emduggan@mit.edu\"\n",
        "Entrez.api_key = \"2e5155aba559345711a3af676cb6c6703608\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBDJ-NrRXViX",
        "outputId": "a2f79d3f-272c-4be3-cdc9-61fd5e4c2366"
      },
      "id": "kBDJ-NrRXViX",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n",
            "--2025-05-08 02:40:20--  https://raw.githubusercontent.com/emd-aquila/cs3-biodiversity/main/data/unique_genus_species.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1185895 (1.1M) [text/plain]\n",
            "Saving to: ‚Äòmyfile.csv‚Äô\n",
            "\n",
            "myfile.csv          100%[===================>]   1.13M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-05-08 02:40:21 (15.8 MB/s) - ‚Äòmyfile.csv‚Äô saved [1185895/1185895]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating local clone of GitHub repository for file storage"
      ],
      "metadata": {
        "id": "OuwkOnoIzZC6"
      },
      "id": "OuwkOnoIzZC6"
    },
    {
      "cell_type": "code",
      "source": [
        "# if needed to clear existing clone\n",
        "!rm -rf cs3-biodiversity\n",
        "\n",
        "# get access code and clone repo\n",
        "os.environ[\"GITHUB_TOKEN\"] = getpass(\"üîê Enter your GitHub token: \")\n",
        "token = os.environ[\"GITHUB_TOKEN\"]\n",
        "repo_url = f\"https://emd-aquila:{token}@github.com/emd-aquila/cs3-biodiversity.git\"\n",
        "\n",
        "!git clone {repo_url}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcjW9I7KuPMr",
        "outputId": "12d707d3-6ff9-4e54-ccc4-3641b51363d4"
      },
      "id": "JcjW9I7KuPMr",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîê Enter your GitHub token: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Cloning into 'cs3-biodiversity'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 41 (delta 19), reused 6 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (41/41), 449.20 KiB | 3.77 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining functions to query database APIs and search for species"
      ],
      "metadata": {
        "id": "rRn4IJJ5zfaU"
      },
      "id": "rRn4IJJ5zfaU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses an email and API key to query the NCBI database\n",
        "def ncbi_query(term):\n",
        "    try:\n",
        "        search = Entrez.esearch(db=\"taxonomy\", term=term, retmode=\"xml\")\n",
        "        result = Entrez.read(search)\n",
        "        if result[\"IdList\"]:\n",
        "            taxid = result[\"IdList\"][0]\n",
        "            fetch = Entrez.efetch(db=\"taxonomy\", id=taxid, retmode=\"xml\")\n",
        "            record = Entrez.read(fetch)[0]\n",
        "            lineage = record.get(\"LineageEx\", [])\n",
        "            class_entry = next((r for r in lineage if r.get(\"Rank\") == \"class\"), None)\n",
        "            return class_entry[\"ScientificName\"] if class_entry else None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå NCBI lookup error for {term}: {e}\")\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "# Queries the Categories of Life database\n",
        "def col_query(term):\n",
        "    url = f\"https://api.catalogueoflife.org/nameusage/search?q={term}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data['total'] > 0:\n",
        "            result = data['result'][0]\n",
        "            lineage = result.get('classification', [])\n",
        "            class_entry = next((r for r in lineage if r.get('rank') == 'class'), None)\n",
        "            return class_entry['name'] if class_entry else None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå COL lookup error for {term}: {e}\")\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "# Queries the WoRMS database\n",
        "def worms_query(term):\n",
        "    url = f\"http://www.marinespecies.org/rest/AphiaRecordsByName/{term}?like=false&marine_only=false\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data:\n",
        "            return data[0].get('class')\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå WoRMS lookup error for {term}: {e}\")\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "# Queries the GBIF Database\n",
        "def gbif_query(term):\n",
        "    url = f\"https://api.gbif.org/v1/species/match?name={term}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data.get(\"class\"):\n",
        "            return data[\"class\"]\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå GBIF lookup error for {term}: {e}\")\n",
        "        return None\n",
        "    return None"
      ],
      "metadata": {
        "id": "bvbqxn05byoo"
      },
      "id": "bvbqxn05byoo",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Searches for the species in the specified DB, first by species and then by genus\n",
        "def search_term(scientific_name, db_type):\n",
        "    \"\"\"\n",
        "    Search for the taxonomic class of a species in a specified database.\n",
        "\n",
        "    Args:\n",
        "        scientific_name (str): The full species name to search.\n",
        "        db_type (str): One of 'NCBI', 'COL', 'WORMS', 'GBIF'.\n",
        "\n",
        "    Returns:\n",
        "        str or None: The class name if found, else None.\n",
        "    \"\"\"\n",
        "\n",
        "    # üîç First try full species name\n",
        "    if db_type.upper() == 'NCBI':\n",
        "        result = ncbi_query(scientific_name)\n",
        "    elif db_type.upper() == 'COL':\n",
        "        result = col_query(scientific_name)\n",
        "    elif db_type.upper() == 'GBIF':\n",
        "        result = gbif_query(scientific_name)\n",
        "    elif db_type.upper() == 'WORMS':\n",
        "        result = worms_query(scientific_name)\n",
        "    else:\n",
        "        raise ValueError(\"db_type must be one of 'NCBI', 'COL', 'WORMS', or 'GBIF'.\")\n",
        "\n",
        "    if result:\n",
        "        return result\n",
        "\n",
        "    # üîÑ Fallback: try genus only\n",
        "    genus = scientific_name.split()[0]\n",
        "    if genus != scientific_name:\n",
        "        print(f\"üîÑ Fallback to genus: {genus}\")\n",
        "        if db_type.upper() == 'NCBI':\n",
        "            return ncbi_query(genus)\n",
        "        elif db_type.upper() == 'COL':\n",
        "            return col_query(genus)\n",
        "        elif db_type.upper() == 'WORMS':\n",
        "            return worms_query(genus)\n",
        "        elif db_type.upper() == 'GBIF':\n",
        "            return gbif_query(genus)\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "No0o6J-liG8P"
      },
      "id": "No0o6J-liG8P",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_ssh_and_push(output_filename,\n",
        "                                 repo_name=\"cs3-biodiversity\",\n",
        "                                 subfolder=\"biotimes-with-class-label\",\n",
        "                                 github_username=\"emd-aquila\",\n",
        "                                 github_email=\"emduggan@mit.edu\",\n",
        "                                 github_name=\"Eli Duggan\"):\n",
        "    \"\"\"\n",
        "    Set up SSH (if needed) and push a batch output file to a subfolder in your GitHub repo using SSH.\n",
        "\n",
        "    Args:\n",
        "        output_filename (str): The CSV filename to push (already saved locally).\n",
        "        repo_name (str): Local folder name of the GitHub repo.\n",
        "        subfolder (str): Subfolder inside the repo to store the file.\n",
        "        github_username (str): Your GitHub username.\n",
        "        github_email (str): Your GitHub email.\n",
        "        github_name (str): Your full name for git config.\n",
        "    \"\"\"\n",
        "\n",
        "    # ‚úÖ Add GitHub to known_hosts to prevent verification errors\n",
        "    print(\"üîë Adding GitHub.com to known_hosts (if not already added)...\")\n",
        "    !mkdir -p ~/.ssh\n",
        "    !ssh-keyscan github.com >> ~/.ssh/known_hosts\n",
        "\n",
        "    # ‚úÖ Check if repo folder exists, clone if needed\n",
        "    if not os.path.exists(repo_name):\n",
        "        print(f\"üì• Repo folder '{repo_name}' not found. Cloning with SSH...\")\n",
        "        !git clone git@github.com:{github_username}/{repo_name}.git\n",
        "    else:\n",
        "        print(f\"‚úÖ Repo folder '{repo_name}' already exists.\")\n",
        "\n",
        "    # ‚úÖ Create the subfolder inside the repo if it doesn't exist\n",
        "    subfolder_path = f\"{repo_name}/{subfolder}\"\n",
        "    os.makedirs(subfolder_path, exist_ok=True)\n",
        "\n",
        "    # ‚úÖ Copy the batch result into the subfolder\n",
        "    shutil.copy(output_filename, f\"{subfolder_path}/{output_filename}\")\n",
        "    # print(f\"‚úÖ Copied {output_filename} into {subfolder_path}/\")\n",
        "\n",
        "    # ‚úÖ Push to GitHub\n",
        "    %cd {repo_name}\n",
        "\n",
        "    # Set Git config (only needed once)\n",
        "    !git config user.email \"{github_email}\"\n",
        "    !git config user.name \"{github_name}\"\n",
        "\n",
        "    # Set remote to SSH (just in case)\n",
        "    !git remote set-url origin git@github.com:{github_username}/{repo_name}.git\n",
        "\n",
        "    # Add, commit, push\n",
        "    !git add {subfolder}/{output_filename}\n",
        "    !git commit -m \"Add batch output {output_filename} to {subfolder}/\" || echo \"No changes to commit.\"\n",
        "    !git push origin main\n",
        "\n",
        "    # ‚úÖ Return to root directory\n",
        "    %cd ..\n"
      ],
      "metadata": {
        "id": "c2txzoCM49oD"
      },
      "id": "c2txzoCM49oD",
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def push_combined_csv_to_github(combined_filename=\"all_species_with_class.csv\",\n",
        "                                repo_name=\"cs3-biodiversity\",\n",
        "                                subfolder=\"biotimes-with-class-label\",\n",
        "                                github_username=\"emd-aquila\",\n",
        "                                github_email=\"emduggan@mit.edu\",\n",
        "                                github_name=\"Eli Duggan\"):\n",
        "    \"\"\"\n",
        "    Push the combined CSV file to a subfolder in your GitHub repo using SSH.\n",
        "    \"\"\"\n",
        "    # ‚úÖ Build the full subfolder path\n",
        "    subfolder_path = f\"{repo_name}/{subfolder}\"\n",
        "\n",
        "    # ‚úÖ Make sure the subfolder exists inside the repo\n",
        "    os.makedirs(subfolder_path, exist_ok=True)\n",
        "\n",
        "    # ‚úÖ Move the combined CSV into the subfolder\n",
        "    dest_path = f\"{subfolder_path}/{combined_filename}\"\n",
        "    if not os.path.exists(dest_path):\n",
        "        shutil.move(combined_filename, dest_path)\n",
        "        print(f\"‚úÖ Moved {combined_filename} into {subfolder_path}/\")\n",
        "    else:\n",
        "        print(f\"‚úÖ {combined_filename} already exists in {subfolder_path}/\")\n",
        "\n",
        "    # ‚úÖ Push to GitHub\n",
        "    %cd {repo_name}\n",
        "\n",
        "    !git config user.email \"{github_email}\"\n",
        "    !git config user.name \"{github_name}\"\n",
        "    !git remote set-url origin git@github.com:{github_username}/{repo_name}.git\n",
        "\n",
        "    !git add {subfolder}/{combined_filename}\n",
        "    !git commit -m \"Add combined species class CSV to {subfolder}/\" || echo \"No changes to commit.\"\n",
        "    !git push origin main\n",
        "\n",
        "    %cd ..\n"
      ],
      "metadata": {
        "id": "R4cS-WGh-Jt2"
      },
      "id": "R4cS-WGh-Jt2",
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batching Data and Loading the Cache"
      ],
      "metadata": {
        "id": "_6IvUjjRzmo6"
      },
      "id": "_6IvUjjRzmo6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching data and saving\n"
      ],
      "metadata": {
        "id": "Se85TdQFzs_x"
      },
      "id": "Se85TdQFzs_x"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 15\n",
        "num_batches = math.ceil(len(df_all) / batch_size)\n",
        "\n",
        "# Save each batch\n",
        "for i in range(num_batches):\n",
        "    batch_df = df_all.iloc[i*batch_size : (i+1)*batch_size]\n",
        "    batch_file = f\"species_batch_{i+1:03d}.csv\"\n",
        "    batch_df.to_csv(batch_file, index=False)\n",
        "    # print(f\"Saved {batch_file}\")"
      ],
      "metadata": {
        "id": "3UWDlYsyiyMU",
        "collapsed": true
      },
      "id": "3UWDlYsyiyMU",
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading batch files and caching files"
      ],
      "metadata": {
        "id": "lF0gQd8Wzwlt"
      },
      "id": "lF0gQd8Wzwlt"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_filename = \"species_batch_001.csv\"\n",
        "\n",
        "# Cache files\n",
        "taxid_cache_file = batch_filename.replace(\".csv\", \"_taxid_cache.csv\")\n",
        "class_cache_file = batch_filename.replace(\".csv\", \"_class_cache.csv\")\n",
        "\n",
        "# Load batch CSV\n",
        "df_batch = pd.read_csv(batch_filename)\n",
        "species_names = df_batch[\"GENUS_SPECIES\"].dropna().unique()\n",
        "print(f\"‚úÖ Loaded {len(species_names)} species from {batch_filename}\")\n",
        "\n",
        "# üîÑ Load class cache if it exists\n",
        "if pd.io.common.file_exists(class_cache_file):\n",
        "    cached_df = pd.read_csv(class_cache_file)\n",
        "    tax_class_dict = dict(zip(cached_df[\"GENUS_SPECIES\"], cached_df[\"taxonomic_class\"]))\n",
        "    print(f\"üîÑ Loaded {len(tax_class_dict)} classes from cache.\")\n",
        "else:\n",
        "    tax_class_dict = {}\n",
        "\n",
        "to_process = [s for s in species_names if s not in tax_class_dict]\n",
        "print(f\"üîé {len(to_process)} species left to process.\")"
      ],
      "metadata": {
        "id": "WNSxbW3Pi8zx",
        "outputId": "65451d04-950b-4567-c0b2-17b39b766a6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WNSxbW3Pi8zx",
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded 15 species from species_batch_001.csv\n",
            "üîé 15 species left to process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clear cache (if needed)"
      ],
      "metadata": {
        "id": "wpjplRDuz6G0"
      },
      "id": "wpjplRDuz6G0"
    },
    {
      "cell_type": "code",
      "source": [
        "class_cache_file = batch_filename.replace(\".csv\", \"_class_cache.csv\")\n",
        "\n",
        "# Delete class cache\n",
        "if os.path.exists(class_cache_file):\n",
        "    os.remove(class_cache_file)\n",
        "    print(f\"üóëÔ∏è Deleted {class_cache_file}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è No cache file found for {class_cache_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4jvsfJures6",
        "outputId": "e8e67049-ddaa-4007-8691-af2b9f1cd847"
      },
      "id": "Q4jvsfJures6",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üóëÔ∏è Deleted species_batch_001_class_cache.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Species Search Loop"
      ],
      "metadata": {
        "id": "EB3j9upSz_Fo"
      },
      "id": "EB3j9upSz_Fo"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Search Loop of all species in this CSV batch through databases\"\"\"\n",
        "\n",
        "skipped_morphospecies = 0\n",
        "skipped_species_list = []\n",
        "\n",
        "for i, species_name in enumerate(tqdm(to_process, desc=\"Fetching Classes (all DBs)\")):\n",
        "    # üö´ Skip morphospecies\n",
        "    if \"morphospecies\" in species_name.lower():\n",
        "        tax_class_dict[species_name] = None\n",
        "        skipped_morphospecies += 1\n",
        "        skipped_species_list.append(species_name)\n",
        "        continue\n",
        "\n",
        "    # ‚úÖ First: NCBI\n",
        "    class_name = search_term(species_name, db_type=\"NCBI\")\n",
        "\n",
        "    # üü° Fallbacks\n",
        "    if not class_name:\n",
        "        class_name = search_term(species_name, db_type=\"COL\")\n",
        "    if not class_name:\n",
        "        class_name = search_term(species_name, db_type=\"WORMS\")\n",
        "    if not class_name:\n",
        "        class_name = search_term(species_name, db_type=\"GBIF\")\n",
        "\n",
        "    tax_class_dict[species_name] = class_name\n",
        "\n",
        "    # üíæ Save cache after each species\n",
        "    pd.DataFrame([\n",
        "        {\"GENUS_SPECIES\": k, \"taxonomic_class\": v} for k, v in tax_class_dict.items()\n",
        "    ]).to_csv(class_cache_file, index=False)\n",
        "\n",
        "    # ‚úÖ Periodic log every 100 species\n",
        "    # if (i + 1) % 100 == 0:\n",
        "    #     print(f\"üîÑ Processed {i + 1}/{len(to_process)} species...\")\n",
        "\n",
        "    time.sleep(0.1)\n",
        "\n",
        "\n",
        "\"\"\"End summary of number of skipped species\"\"\"\n",
        "if skipped_species_list:\n",
        "    skipped_filename = batch_filename.replace(\".csv\", \"_skipped_morphospecies.csv\")\n",
        "    pd.DataFrame({\"GENUS_SPECIES\": skipped_species_list}).to_csv(skipped_filename, index=False)\n",
        "    print(f\"üóÇÔ∏è Skipped species saved to {skipped_filename}\")\n",
        "else:\n",
        "    print(\"‚úÖ No morphospecies were skipped in this batch.\")\n",
        "\n",
        "\n",
        "\"\"\"Saving our results\"\"\"\n",
        "cached_df = pd.read_csv(class_cache_file)\n",
        "final_df = df_batch.merge(cached_df, on=\"GENUS_SPECIES\", how=\"left\")\n",
        "\n",
        "# ‚úÖ Save the final batch result\n",
        "output_filename = batch_filename.replace(\".csv\", \"_with_class.csv\")\n",
        "final_df = df_batch.merge(pd.read_csv(class_cache_file), on=\"GENUS_SPECIES\", how=\"left\")\n",
        "final_df.to_csv(output_filename, index=False)\n",
        "print(f\"‚úÖ Final output saved as {output_filename}\")\n",
        "\n",
        "# ‚úÖ Push to GitHub with one simple call\n",
        "setup_ssh_and_push(output_filename)"
      ],
      "metadata": {
        "id": "p8f-TzmxibD_",
        "outputId": "bd85af04-b83e-4871-96c4-645c05ce8719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p8f-TzmxibD_",
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching Classes (all DBs):  27%|‚ñà‚ñà‚ñã       | 4/15 [00:01<00:04,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Fallback to genus: Populus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching Classes (all DBs): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:06<00:00,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ No morphospecies were skipped in this batch.\n",
            "‚úÖ Final output saved as species_batch_001_with_class.csv\n",
            "üîë Adding GitHub.com to known_hosts (if not already added)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-50e45de6\n",
            "# github.com:22 SSH-2.0-50e45de6\n",
            "# github.com:22 SSH-2.0-50e45de6\n",
            "# github.com:22 SSH-2.0-50e45de6\n",
            "# github.com:22 SSH-2.0-50e45de6\n",
            "‚úÖ Repo folder 'cs3-biodiversity' already exists.\n",
            "/content/cs3-biodiversity/cs3-biodiversity\n",
            "[main abeecae] Add batch output species_batch_001_with_class.csv to biotimes-with-class-label/\n",
            " 1 file changed, 5 insertions(+)\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 516 bytes | 516.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To github.com:emd-aquila/cs3-biodiversity.git\n",
            "   dfaca0f..abeecae  main -> main\n",
            "/content/cs3-biodiversity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Collation of Results"
      ],
      "metadata": {
        "id": "LIHugZQJ0D-F"
      },
      "id": "LIHugZQJ0D-F"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd cs3-biodiversity\n",
        "!git pull origin main\n",
        "%cd ..\n",
        "\n",
        "batch_files = sorted(glob.glob(\"cs3-biodiversity/biotimes-with-class-label/species_batch_*_with_class.csv\"))\n",
        "\n",
        "combined_df = pd.concat([pd.read_csv(f) for f in batch_files], ignore_index=True)\n",
        "combined_df.to_csv(\"all_species_with_class.csv\", index=False)\n",
        "print(\"‚úÖ Combined file saved as all_species_with_class.csv\")\n",
        "\n",
        "push_combined_csv_to_github(\"all_species_with_class.csv\")"
      ],
      "metadata": {
        "id": "QHUxXHIE9LcC",
        "outputId": "3605b36a-44e7-423c-b8ba-6a7633f5c65a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QHUxXHIE9LcC",
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cs3-biodiversity/cs3-biodiversity\n",
            "From github.com:emd-aquila/cs3-biodiversity\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "/content/cs3-biodiversity\n",
            "‚úÖ Combined file saved as all_species_with_class.csv\n",
            "‚úÖ Moved all_species_with_class.csv into cs3-biodiversity/biotimes-with-class-label/\n",
            "/content/cs3-biodiversity/cs3-biodiversity\n",
            "[main 72bef5f] Add combined species class CSV to biotimes-with-class-label/\n",
            " 1 file changed, 16 insertions(+)\n",
            " create mode 100644 biotimes-with-class-label/all_species_with_class.csv\n",
            "Enumerating objects: 5, done.\n",
            "Counting objects: 100% (5/5), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (3/3), 362 bytes | 362.00 KiB/s, done.\n",
            "Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To github.com:emd-aquila/cs3-biodiversity.git\n",
            "   a08521f..72bef5f  main -> main\n",
            "/content/cs3-biodiversity\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}