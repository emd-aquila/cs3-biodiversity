{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d9e16aaf",
      "metadata": {
        "id": "d9e16aaf"
      },
      "source": [
        "# Genus/Species to Class Converter\n",
        "This notebook contains code to convert the genus/species listing from the BioTIME-DB to taxonomic class using Biopython and calling upon the NCBI, COL, GBIF, and WORMS databases, in that order."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary packages and get CSV file from GitHub"
      ],
      "metadata": {
        "id": "lrrHbca8zLWx"
      },
      "id": "lrrHbca8zLWx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages and set NCBI API information.\n",
        "!pip install biopython tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "from Bio import Entrez\n",
        "import time\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from getpass import getpass\n",
        "\n",
        "! wget https://raw.githubusercontent.com/emd-aquila/cs3-biodiversity/main/data/unique_genus_species.csv -O myfile.csv\n",
        "df_all = pd.read_csv(\"myfile.csv\")\n",
        "\n",
        "Entrez.email = \"emduggan@mit.edu\"\n",
        "Entrez.api_key = \"2e5155aba559345711a3af676cb6c6703608\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBDJ-NrRXViX",
        "outputId": "a2f79d3f-272c-4be3-cdc9-61fd5e4c2366"
      },
      "id": "kBDJ-NrRXViX",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n",
            "--2025-05-08 02:40:20--  https://raw.githubusercontent.com/emd-aquila/cs3-biodiversity/main/data/unique_genus_species.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1185895 (1.1M) [text/plain]\n",
            "Saving to: ‚Äòmyfile.csv‚Äô\n",
            "\n",
            "myfile.csv          100%[===================>]   1.13M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-05-08 02:40:21 (15.8 MB/s) - ‚Äòmyfile.csv‚Äô saved [1185895/1185895]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating local clone of GitHub repository for file storage"
      ],
      "metadata": {
        "id": "OuwkOnoIzZC6"
      },
      "id": "OuwkOnoIzZC6"
    },
    {
      "cell_type": "code",
      "source": [
        "# if needed to clear existing clone\n",
        "!rm -rf cs3-biodiversity\n",
        "\n",
        "# get access code and clone repo\n",
        "os.environ[\"GITHUB_TOKEN\"] = getpass(\"üîê Enter your GitHub token: \")\n",
        "token = os.environ[\"GITHUB_TOKEN\"]\n",
        "repo_url = f\"https://emd-aquila:{token}@github.com/emd-aquila/cs3-biodiversity.git\"\n",
        "\n",
        "!git clone {repo_url}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcjW9I7KuPMr",
        "outputId": "a7ab4018-5a00-4771-d6e6-55e354546604"
      },
      "id": "JcjW9I7KuPMr",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîê Enter your GitHub token: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Cloning into 'cs3-biodiversity'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 35 (delta 15), reused 6 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (35/35), 445.70 KiB | 4.20 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining functions to query database APIs and search for species"
      ],
      "metadata": {
        "id": "rRn4IJJ5zfaU"
      },
      "id": "rRn4IJJ5zfaU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses an email and API key to query the NCBI database\n",
        "def ncbi_query(term):\n",
        "    try:\n",
        "        search = Entrez.esearch(db=\"taxonomy\", term=term, retmode=\"xml\")\n",
        "        result = Entrez.read(search)\n",
        "        if result[\"IdList\"]:\n",
        "            taxid = result[\"IdList\"][0]\n",
        "            fetch = Entrez.efetch(db=\"taxonomy\", id=taxid, retmode=\"xml\")\n",
        "            record = Entrez.read(fetch)[0]\n",
        "            lineage = record.get(\"LineageEx\", [])\n",
        "            class_entry = next((r for r in lineage if r.get(\"Rank\") == \"class\"), None)\n",
        "            return class_entry[\"ScientificName\"] if class_entry else None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå NCBI lookup error for {term}: {e}\")\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "# Queries the Categories of Life database\n",
        "def col_query(term):\n",
        "    url = f\"https://api.catalogueoflife.org/nameusage/search?q={term}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data['total'] > 0:\n",
        "            result = data['result'][0]\n",
        "            lineage = result.get('classification', [])\n",
        "            class_entry = next((r for r in lineage if r.get('rank') == 'class'), None)\n",
        "            return class_entry['name'] if class_entry else None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå COL lookup error for {term}: {e}\")\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "# Queries the WoRMS database\n",
        "def worms_query(term):\n",
        "    url = f\"http://www.marinespecies.org/rest/AphiaRecordsByName/{term}?like=false&marine_only=false\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data:\n",
        "            return data[0].get('class')\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå WoRMS lookup error for {term}: {e}\")\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "# Queries the GBIF Database\n",
        "def gbif_query(term):\n",
        "    url = f\"https://api.gbif.org/v1/species/match?name={term}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data.get(\"class\"):\n",
        "            return data[\"class\"]\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå GBIF lookup error for {term}: {e}\")\n",
        "        return None\n",
        "    return None"
      ],
      "metadata": {
        "id": "bvbqxn05byoo"
      },
      "id": "bvbqxn05byoo",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Searches for the species in the specified DB, first by species and then by genus\n",
        "def search_term(scientific_name, db_type):\n",
        "    \"\"\"\n",
        "    Search for the taxonomic class of a species in a specified database.\n",
        "\n",
        "    Args:\n",
        "        scientific_name (str): The full species name to search.\n",
        "        db_type (str): One of 'NCBI', 'COL', 'WORMS', 'GBIF'.\n",
        "\n",
        "    Returns:\n",
        "        str or None: The class name if found, else None.\n",
        "    \"\"\"\n",
        "\n",
        "    # üîç First try full species name\n",
        "    if db_type.upper() == 'NCBI':\n",
        "        result = ncbi_query(scientific_name)\n",
        "    elif db_type.upper() == 'COL':\n",
        "        result = col_query(scientific_name)\n",
        "    elif db_type.upper() == 'GBIF':\n",
        "        result = gbif_query(scientific_name)\n",
        "    elif db_type.upper() == 'WORMS':\n",
        "        result = worms_query(scientific_name)\n",
        "    else:\n",
        "        raise ValueError(\"db_type must be one of 'NCBI', 'COL', 'WORMS', or 'GBIF'.\")\n",
        "\n",
        "    if result:\n",
        "        return result\n",
        "\n",
        "    # üîÑ Fallback: try genus only\n",
        "    genus = scientific_name.split()[0]\n",
        "    if genus != scientific_name:\n",
        "        print(f\"üîÑ Fallback to genus: {genus}\")\n",
        "        if db_type.upper() == 'NCBI':\n",
        "            return ncbi_query(genus)\n",
        "        elif db_type.upper() == 'COL':\n",
        "            return col_query(genus)\n",
        "        elif db_type.upper() == 'WORMS':\n",
        "            return worms_query(genus)\n",
        "        elif db_type.upper() == 'GBIF':\n",
        "            return gbif_query(genus)\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "No0o6J-liG8P"
      },
      "id": "No0o6J-liG8P",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batching Data and Loading the Cache"
      ],
      "metadata": {
        "id": "_6IvUjjRzmo6"
      },
      "id": "_6IvUjjRzmo6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching data and saving\n"
      ],
      "metadata": {
        "id": "Se85TdQFzs_x"
      },
      "id": "Se85TdQFzs_x"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "num_batches = math.ceil(len(df_all) / batch_size)\n",
        "\n",
        "# Save each batch\n",
        "for i in range(num_batches):\n",
        "    batch_df = df_all.iloc[i*batch_size : (i+1)*batch_size]\n",
        "    batch_file = f\"species_batch_{i+1:03d}.csv\"\n",
        "    batch_df.to_csv(batch_file, index=False)\n",
        "    # print(f\"Saved {batch_file}\")"
      ],
      "metadata": {
        "id": "3UWDlYsyiyMU",
        "collapsed": true
      },
      "id": "3UWDlYsyiyMU",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading batch files and caching files"
      ],
      "metadata": {
        "id": "lF0gQd8Wzwlt"
      },
      "id": "lF0gQd8Wzwlt"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_filename = \"species_batch_001.csv\"\n",
        "\n",
        "# Cache files\n",
        "taxid_cache_file = batch_filename.replace(\".csv\", \"_taxid_cache.csv\")\n",
        "class_cache_file = batch_filename.replace(\".csv\", \"_class_cache.csv\")\n",
        "\n",
        "# Load batch CSV\n",
        "df_batch = pd.read_csv(batch_filename)\n",
        "species_names = df_batch[\"GENUS_SPECIES\"].dropna().unique()\n",
        "print(f\"‚úÖ Loaded {len(species_names)} species from {batch_filename}\")\n",
        "\n",
        "# üîÑ Load class cache if it exists\n",
        "if pd.io.common.file_exists(class_cache_file):\n",
        "    cached_df = pd.read_csv(class_cache_file)\n",
        "    tax_class_dict = dict(zip(cached_df[\"GENUS_SPECIES\"], cached_df[\"taxonomic_class\"]))\n",
        "    print(f\"üîÑ Loaded {len(tax_class_dict)} classes from cache.\")\n",
        "else:\n",
        "    tax_class_dict = {}\n",
        "\n",
        "to_process = [s for s in species_names if s not in tax_class_dict]\n",
        "print(f\"üîé {len(to_process)} species left to process.\")"
      ],
      "metadata": {
        "id": "WNSxbW3Pi8zx",
        "outputId": "862de5ec-ef1c-484a-b027-89fe08c715d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WNSxbW3Pi8zx",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded 10 species from species_batch_001.csv\n",
            "üîé 10 species left to process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clear cache (if needed)"
      ],
      "metadata": {
        "id": "wpjplRDuz6G0"
      },
      "id": "wpjplRDuz6G0"
    },
    {
      "cell_type": "code",
      "source": [
        "class_cache_file = batch_filename.replace(\".csv\", \"_class_cache.csv\")\n",
        "\n",
        "# Delete class cache\n",
        "if os.path.exists(class_cache_file):\n",
        "    os.remove(class_cache_file)\n",
        "    print(f\"üóëÔ∏è Deleted {class_cache_file}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è No cache file found for {class_cache_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4jvsfJures6",
        "outputId": "6db72cd6-35c3-479c-8e3e-595359fe11ec"
      },
      "id": "Q4jvsfJures6",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üóëÔ∏è Deleted species_batch_001_class_cache.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Species Search Loop"
      ],
      "metadata": {
        "id": "EB3j9upSz_Fo"
      },
      "id": "EB3j9upSz_Fo"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Search Loop of all species in this CSV batch through databases\"\"\"\n",
        "\n",
        "skipped_morphospecies = 0\n",
        "skipped_species_list = []\n",
        "\n",
        "for i, species_name in enumerate(tqdm(to_process, desc=\"Fetching Classes (all DBs)\")):\n",
        "    # üö´ Skip morphospecies\n",
        "    if \"morphospecies\" in species_name.lower():\n",
        "        tax_class_dict[species_name] = None\n",
        "        skipped_morphospecies += 1\n",
        "        skipped_species_list.append(species_name)\n",
        "        continue\n",
        "\n",
        "    # ‚úÖ First: NCBI\n",
        "    class_name = search_term(species_name, db_type=\"NCBI\")\n",
        "\n",
        "    # üü° Fallbacks\n",
        "    if not class_name:\n",
        "        class_name = search_term(species_name, db_type=\"COL\")\n",
        "    if not class_name:\n",
        "        class_name = search_term(species_name, db_type=\"WORMS\")\n",
        "    if not class_name:\n",
        "        class_name = search_term(species_name, db_type=\"GBIF\")\n",
        "\n",
        "    tax_class_dict[species_name] = class_name\n",
        "\n",
        "    # üíæ Save cache after each species\n",
        "    pd.DataFrame([\n",
        "        {\"GENUS_SPECIES\": k, \"taxonomic_class\": v} for k, v in tax_class_dict.items()\n",
        "    ]).to_csv(class_cache_file, index=False)\n",
        "\n",
        "    # ‚úÖ Periodic log every 100 species\n",
        "    # if (i + 1) % 100 == 0:\n",
        "    #     print(f\"üîÑ Processed {i + 1}/{len(to_process)} species...\")\n",
        "\n",
        "    time.sleep(0.1)\n",
        "\n",
        "\n",
        "\"\"\"End summary of number of skipped species\"\"\"\n",
        "\n",
        "print(f\"üö© Skipped {skipped_morphospecies} species containing 'morphospecies'.\")\n",
        "\n",
        "if skipped_species_list:\n",
        "    skipped_filename = batch_filename.replace(\".csv\", \"_skipped_morphospecies.csv\")\n",
        "    pd.DataFrame({\"GENUS_SPECIES\": skipped_species_list}).to_csv(skipped_filename, index=False)\n",
        "    print(f\"üóÇÔ∏è Skipped species saved to {skipped_filename}\")\n",
        "else:\n",
        "    print(\"‚úÖ No morphospecies were skipped in this batch.\")\n",
        "\n",
        "\n",
        "\"\"\"Saving our results and pushing to the repo\"\"\"\n",
        "cached_df = pd.read_csv(class_cache_file)\n",
        "final_df = df_batch.merge(cached_df, on=\"GENUS_SPECIES\", how=\"left\")\n",
        "\n",
        "# ‚úÖ Save the final batch result\n",
        "output_filename = batch_filename.replace(\".csv\", \"_with_class.csv\")\n",
        "final_df.to_csv(output_filename, index=False)\n",
        "print(f\"‚úÖ Final output saved as {output_filename}\")\n",
        "\n",
        "repo_folder = \"cs3-biodiversity\"  # Your repo folder\n",
        "shutil.copy(output_filename, f\"{repo_folder}/{output_filename}\")\n",
        "print(f\"‚úÖ Copied {output_filename} into {repo_folder}/\")\n",
        "\n",
        "# Git push\n",
        "token = os.environ[\"GITHUB_TOKEN\"]\n",
        "remote_url = f\"https://emd-aquila:{token}@github.com/emd-aquila/cs3-biodiversity.git\"\n",
        "\n",
        "%cd cs3-biodiversity\n",
        "!git config user.email \"emduggan@mit.edu\"\n",
        "!git config user.name \"Eli Duggan\"\n",
        "!git remote set-url origin {remote_url}\n",
        "!git add {output_filename}\n",
        "!git commit -m \"Add batch output {output_filename}\"\n",
        "!git push origin main\n",
        "%cd .."
      ],
      "metadata": {
        "id": "p8f-TzmxibD_",
        "outputId": "3d657a18-b457-42b1-ef1a-607c8fbdc699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p8f-TzmxibD_",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching Classes (all DBs):  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:02<00:03,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Fallback to genus: Populus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching Classes (all DBs): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:04<00:00,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üö© Skipped 0 species containing 'morphospecies'.\n",
            "‚úÖ No morphospecies were skipped in this batch.\n",
            "‚úÖ Final output saved as species_batch_001_with_class.csv\n",
            "‚úÖ Copied species_batch_001_with_class.csv into cs3-biodiversity/\n",
            "/content/cs3-biodiversity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 750beeb] Add batch output species_batch_001_with_class.csv\n",
            " 1 file changed, 11 insertions(+)\n",
            " create mode 100644 species_batch_001_with_class.csv\n",
            "remote: Invalid username or password.\n",
            "fatal: Authentication failed for 'https://github.com/emd-aquila/cs3-biodiversity.git/'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Collation of Results"
      ],
      "metadata": {
        "id": "LIHugZQJ0D-F"
      },
      "id": "LIHugZQJ0D-F"
    },
    {
      "cell_type": "code",
      "source": [
        "# COMBINE ALL BATCHED CSV RESULTS 1-9 - only run at end\n",
        "\n",
        "# ‚úÖ Match all batch output files\n",
        "batch_files = sorted(glob.glob(\"species_batch_*_with_class.csv\"))\n",
        "\n",
        "# ‚úÖ Combine them into one DataFrame\n",
        "combined_df = pd.concat([pd.read_csv(f) for f in batch_files], ignore_index=True)\n",
        "\n",
        "# ‚úÖ Save the final combined result\n",
        "combined_df.to_csv(\"all_species_with_class.csv\", index=False)\n",
        "print(\"‚úÖ Combined file saved as all_species_with_class.csv\")"
      ],
      "metadata": {
        "id": "iITSYIEAmx05"
      },
      "id": "iITSYIEAmx05",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}